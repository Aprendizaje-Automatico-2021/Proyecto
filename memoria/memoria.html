<!DOCTYPE html>
<html>
<head>
<title>memoria.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="bodyperfomance-classification">BodyPerfomance Classification</h1>
<table>
<thead>
<tr>
<th>Autores</th>
<th>email</th>
</tr>
</thead>
<tbody>
<tr>
<td>Clara Daniela Sima</td>
<td>csima@ucm.es</td>
</tr>
<tr>
<td>Stiven Arias Giraldo</td>
<td>starias@ucm.es</td>
</tr>
</tbody>
</table>
<p>Resultados del proyecto final de la asignatura de <strong><code>Aprendizaje Automático y Minería de Datos</code></strong> del grado de <strong><code>Desarrollo de Videojuegos</code></strong> de la <strong><code>Universidad Complutense de Madrid</code></strong></p>
<h1 id="descripci%C3%B3n">Descripción</h1>
<p>La base de datos que hemos escogido está compuesta por múltiples atributos que describen características físicas de diversas personas. Por ser más concretos, contamos con <code>13393 ejemplos de entrenamiento</code>, es decir, 13393 personas, de las cuales tenemos <code>11 atributos</code> y un resultado para cada una.</p>
<p>Esto quiere decir que nuestro dataset está compuesto por una <code>matriz de (13393, 12) dimensiones</code>, donde la última columna nos indica la calificación de un <em><code>entrenamiento físico</code></em> de cada persona en función del resto de atributos, pudiendo ser <strong><code>A, B, C, D</code></strong> dicha calificación, siendo <strong>A</strong> el mejor resultado posible.</p>
<p><img src="https://user-images.githubusercontent.com/47497948/149372136-b6356d03-dd10-4deb-a039-9ddb2182d937.png" alt="image"></p>
<p><img src="https://user-images.githubusercontent.com/47497948/149371625-e32eefcb-1069-4653-bc3d-71cfeb01bf75.png" alt="image"></p>
<p>Así pues, la idea principal de este proyecto es aprovechar los diferentes algoritmos de aprendizaje automático realizados durante el curso, procesando los diferentes datos para poder determinar qué sistema de aprendizaje resulta más óptimo para clasificar correctamente el <em>dataset</em>.
Cada uno de los sistemas tendrán que predecir cuál ha sido el grado de eficiencia del usuario (A, B, C o D) para finalmente comparar dicha predicción con los datos reales.</p>
<p>Los sistemas son los siguientes: <em>SVM, Regresión logística y Redes Neuronales</em></p>
<h1 id="inicializaci%C3%B3n-y-selecci%C3%B3n-de-los-datos-de-entrenamiento">Inicialización y selección de los datos de entrenamiento</h1>
<p>Dentro del <strong>main.py</strong> tenemos el lanzador del programa, donde importamos los diferentes métodos de los sistemas de clasificación.</p>
<p>Para agilizar el proceso de selección del sistema tenemos una variable <strong><em>system</em></strong> para seleccionar el sistema que se desea probar:</p>
<pre class="hljs"><code><div><span class="hljs-keyword">from</span> svmPerformance <span class="hljs-keyword">import</span> svmClassification <span class="hljs-keyword">as</span> svm
<span class="hljs-keyword">from</span> logisticRegresion <span class="hljs-keyword">import</span> bestPairClassification <span class="hljs-keyword">as</span> pairLog, logisticRegresionClassification <span class="hljs-keyword">as</span> log
<span class="hljs-keyword">from</span> redesNeuronales <span class="hljs-keyword">import</span> neuralNetworkClassification <span class="hljs-keyword">as</span> red_neu
<span class="hljs-keyword">from</span> initData <span class="hljs-keyword">import</span> *


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">main</span><span class="hljs-params">(system=<span class="hljs-number">0</span>)</span>:</span>
    <span class="hljs-comment"># Carga de los datos en un diccionario dataset</span>
    allX, allY, dataset = loadData()
    <span class="hljs-comment"># Fragmentación del dataset</span>
    X, y, Xval, yval, Xtest, ytest = selectingData(allX, allY)

    <span class="hljs-keyword">if</span> system == <span class="hljs-number">0</span>:
        <span class="hljs-comment"># Clasificacion de los datos mediante SVM</span>
        svm(X, y, Xval, yval, Xtest, ytest)
    <span class="hljs-keyword">elif</span> system == <span class="hljs-number">1</span>:
        <span class="hljs-comment"># Clasificacion de los datos mediante Regresión logistica</span>
        log(X, y, Xval, yval, Xtest, ytest)
        <span class="hljs-comment"># Clasificacion de los datos mediante Regresión logistica</span>
        <span class="hljs-comment"># escogiendo el mejor par de atributos</span>
        pairLog(X, y, Xval, yval, Xtest, ytest, dataset)
    <span class="hljs-keyword">elif</span> system == <span class="hljs-number">2</span>:
        <span class="hljs-comment"># Clasificacion de los datos mediante Redes Neuronales</span>
        red_neu(X, y, Xval, yval, Xtest, ytest)
    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>
    
system = <span class="hljs-number">1</span>
main(system)
</div></code></pre>
<p>En primer lugar, se cargan los datos con <strong><code>loadData</code></strong>, donde se lee el <strong>.csv</strong> y se hacen las correspondientes conversiones de datos para obtener matrices de <strong>floats</strong>. Además, tenemos el método <strong><code>plot_coor</code></strong>, el cual nos sirve para dibujar una gráfica que muestra la matriz de correlaciones entre cada par de datos (exceptuando <code>gender</code> y <code>Class</code>, ya que es lo que devuelve <strong><code>df.corr()</code></strong>, además que nuestro sistema va a clasificar los valores en función de Class). Esta matriz de correlaciones nos parece interesante porque con ella se pueden tener otro tipo de observaciones, sin embargo, no es del todo relevante para nuestro sistema de clasificación.</p>
<pre class="hljs"><code><div><span class="hljs-keyword">from</span> tarfile <span class="hljs-keyword">import</span> DIRTYPE
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_corr</span><span class="hljs-params">(df,size=<span class="hljs-number">10</span>)</span>:</span>
    <span class="hljs-string">"""
    Dibuja una matriz de correlaciones por filas y columnas
    para cada par de datos del dataset
    """</span>

    corr = df.corr()
    fig, ax = plt.subplots(figsize=(size, size))
    im = ax.matshow(corr, cmap=<span class="hljs-string">"RdPu"</span>)
    plt.colorbar(im, label=<span class="hljs-string">"Correlación entre los atributos"</span>)
    plt.xticks(range(len(corr.columns)), corr.columns, rotation=<span class="hljs-number">20</span>)
    plt.yticks(range(len(corr.columns)), corr.columns)
        
    values = corr.values
    <span class="hljs-keyword">for</span> (i, j), z <span class="hljs-keyword">in</span> np.ndenumerate(values):
        ax.text(j, i, <span class="hljs-string">'{:0.1f}'</span>.format(z), fontsize=<span class="hljs-number">14</span>, ha=<span class="hljs-string">'center'</span>, va=<span class="hljs-string">'center'</span>)

    plt.show()

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">loadData</span><span class="hljs-params">(disp_corr=False)</span>:</span>
    <span class="hljs-string">"""
    Lectura del dataset que contiene los datos de enetrenamiento del sistema
    """</span>
    <span class="hljs-comment"># Carga de los datos del csv y conversión a diccionario sencillo de atributos</span>
    dataset = pd.read_csv(<span class="hljs-string">"./src/assets/bodyPerformance.csv"</span>)
    dataset.drop_duplicates(inplace=<span class="hljs-literal">True</span>)
    dataset.columns = dataset.columns.str.strip().str.replace(<span class="hljs-string">' '</span>, <span class="hljs-string">'_'</span>)
    dataset.rename(columns={<span class="hljs-string">'class'</span>:<span class="hljs-string">'Class'</span>, <span class="hljs-string">'body_fat_%'</span>:<span class="hljs-string">'body_fat'</span>, 
    <span class="hljs-string">'sit-ups_counts'</span>:<span class="hljs-string">'sit_ups_counts'</span>, <span class="hljs-string">'sit_and_bend_forward_cm'</span>:<span class="hljs-string">'sit_bend_forw_cm'</span>}, inplace=<span class="hljs-literal">True</span>)
    
    <span class="hljs-comment"># El número de elementos del data set es de 14K * 12, por tanto, </span>
    <span class="hljs-comment"># para reducir el tiempo de Debug del programa se va a elegir un grupo reducido</span>
    rows = int(dataset.shape[<span class="hljs-number">0</span>])
    cols = int(dataset.shape[<span class="hljs-number">1</span>] - <span class="hljs-number">1</span>)

    <span class="hljs-comment"># Muestra el gráfico de las correlaciones</span>
    plot_corr(dataset)

    <span class="hljs-comment"># Carga de atributos en matrices de numpy</span>
    features = np.array(dataset.values[:rows, :cols])
    <span class="hljs-comment"># Se consideran hombres = 1, mujeres = 0</span>
    features[:, <span class="hljs-number">1</span>] = (dataset[<span class="hljs-string">'gender'</span>][:rows] == <span class="hljs-string">'M'</span>) * <span class="hljs-number">1</span>
    features = features.astype(np.double)

    <span class="hljs-comment"># Carga de los resultados de cada ejemplo de entrenamiento</span>
    results = np.zeros(rows)  
    test = dataset[<span class="hljs-string">'Class'</span>].values
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(rows):
        results[i] = ord(test[i]) - <span class="hljs-number">64</span>
        
    <span class="hljs-keyword">return</span> features, results, dataset
</div></code></pre>
<p>Hemos separado los datos en 3 grupos: <code>entrenamiento</code>, <code>validación</code> y <code>testing</code> donde la proporción de cada grupo es <code>60%</code>, <code>20%</code> y <code>20%</code> del número total de datos respectivamente.</p>
<pre class="hljs"><code><div><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">selectingData</span><span class="hljs-params">(allX, allY)</span>:</span>
    <span class="hljs-string">"""
    Seleccion de los datos de entrenamiento, 
    de validación y de pruebas
    """</span>
    <span class="hljs-comment"># Se cogerá un 60% de los datos para entrenar</span>
    X = normalizeMatrix(allX[:int(<span class="hljs-number">0.6</span> * np.shape(allX)[<span class="hljs-number">0</span>])])
    y = allY[:int(<span class="hljs-number">0.6</span> * np.shape(allY)[<span class="hljs-number">0</span>])]

    <span class="hljs-comment"># Después se coge un 20% para evaluar</span>
    Xval = normalizeMatrix(allX[int(<span class="hljs-number">0.6</span> * np.shape(allX)[<span class="hljs-number">0</span>]) : int(<span class="hljs-number">0.8</span> * np.shape(allX)[<span class="hljs-number">0</span>])])
    yval = allY[int(<span class="hljs-number">0.6</span> * np.shape(allY)[<span class="hljs-number">0</span>]) : int(<span class="hljs-number">0.8</span> * np.shape(allX)[<span class="hljs-number">0</span>])]

    <span class="hljs-comment"># Por último, el 20% resrtante para testing</span>
    Xtest = normalizeMatrix(allX[int(<span class="hljs-number">0.8</span> * np.shape(allX)[<span class="hljs-number">0</span>]):])
    ytest = allY[int(<span class="hljs-number">0.8</span> * np.shape(allX)[<span class="hljs-number">0</span>]):]

    <span class="hljs-keyword">return</span> X, y, Xval, yval, Xtest, ytest

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">normalizeMatrix</span><span class="hljs-params">(X)</span>:</span>
    <span class="hljs-string">"""
    Normaliza el array X
    xi = (xi - ui) / si
    """</span>
    matriz_normal = np.empty_like(X)

    <span class="hljs-comment"># La media y la varianza de cada columna</span>
    u = np.mean(X, axis=<span class="hljs-number">0</span>)
    s = np.std(X, axis=<span class="hljs-number">0</span>)

    matriz_normal = (X - u) / s
    <span class="hljs-keyword">return</span> matriz_normal
</div></code></pre>
<p>En los valores <strong><em>X</em></strong> guardamos los atributos de cada ejemplo de entrenamiento y en los valores <strong><em>Y</em></strong>, los resultados.</p>
<p>La idea de esta distinción de valores es utilizar los <strong><code>datos de entrenamiento</code></strong> para entrenar el sistema utilizado. A partir de los valores generados por el sistema, se utilizarán los <strong><code>datos de validación</code></strong> para verificar que los valores obtenidos son realmente óptimos y, finalmente, con los <strong><code>datos de testing</code></strong> se pone a prueba el sistema al completo.</p>
<p>Para observar los resultados de nuestros sistemas de clasificación, hemos realizado diversas pruebas, por lo que vamos a mostrar los resultados finales y más relevantes. Además, hemos cogido todos los ejemplos de entrenamiento del dataset porque era lo que mejor resultado nos daba en este caso, es decir, casi 14000 ejemplos de entrenamiento, a pesar de que fueran demasiados.</p>
<h1 id="sistema-svm">Sistema SVM</h1>
<p>En primer lugar, realizamos la clasificación de los datos mediante <strong>SVM</strong> (Support Vector Machine).</p>
<p>Para realizar el entrenamiento con SVM hay que tener en cuenta 2 parámetros: <strong><code>initialValue</code></strong>, <strong><code>iters</code></strong>.</p>
<ul>
<li>
<p><strong>initialValue</strong>: sirve para inicializar tanto el parámetro de regularización <code>C</code> y el parámetro <code>sigma</code>. Ambos valores serán usados en la función <strong>SVC</strong>, la cual está basada en un kernel gaussiano <code>rbf</code> y se irán modificando a través del bucle de entrenamiento.</p>
</li>
<li>
<p><strong>iters</strong>: es el número de iteraciones que habrá para realizar el entrenamiento de los valores <code>C</code> y <code>sigma</code>, es decir, en total habrá <strong><code>iters * iters</code></strong> iteraciones para el entrenamiento.</p>
</li>
</ul>
<p>Durante este proceso, vamos guardando los mejores valores del entrenamiento en función de la puntuación obtenida con los datos de validación <code>Xval, yval</code>.</p>
<pre class="hljs"><code><div><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">svmClassification</span><span class="hljs-params">(X, y, Xval, yval, Xtest, ytest)</span>:</span>
    <span class="hljs-string">"""
    Clasificación de losd atos mediantes SVM
    """</span>
    print(<span class="hljs-string">"Entrenando sistema de clasificacion de bodyPerfomance"</span>)
    initialValue = <span class="hljs-number">0.0001</span>
    iters = <span class="hljs-number">20</span>
    XX = np.insert(X, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, axis = <span class="hljs-number">1</span>)
    XXval = np.insert(Xval, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, axis = <span class="hljs-number">1</span>)
    XXtest = np.insert(Xtest, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, axis = <span class="hljs-number">1</span>)

    svm, params, bestIndex, bestScore, eTraining, eValidation = selectParameters(XX, y, XXval, yval, initialValue, iters)

    reg = params[<span class="hljs-number">0</span>, bestIndex[<span class="hljs-number">0</span>]]
    sigma = params[<span class="hljs-number">1</span>, bestIndex[<span class="hljs-number">1</span>]]

    <span class="hljs-comment"># Precision del svm</span>
    print(<span class="hljs-string">f"Error: <span class="hljs-subst">{<span class="hljs-number">1</span> - bestScore}</span>"</span>)
    print(<span class="hljs-string">f"Mejor reg: <span class="hljs-subst">{reg}</span>"</span>)
    print(<span class="hljs-string">f"Mejor sigma: <span class="hljs-subst">{sigma}</span>"</span>)
    testScore = np.zeros(<span class="hljs-number">3</span>)
    testScore[<span class="hljs-number">0</span>] = svm.score(XX, y)
    print(<span class="hljs-string">f"Precisión sobres los datos de entrenamiento: <span class="hljs-subst">{testScore[<span class="hljs-number">0</span>] * <span class="hljs-number">100</span>}</span>%"</span>)
    testScore[<span class="hljs-number">1</span>] = svm.score(XXval, yval)
    print(<span class="hljs-string">f"Precisión sobres los datos de evaluación: <span class="hljs-subst">{testScore[<span class="hljs-number">1</span>] * <span class="hljs-number">100</span>}</span>%"</span>)
    testScore[<span class="hljs-number">2</span>] = svm.score(XXtest, ytest)
    print(<span class="hljs-string">f"Precisión sobres los datos de testing: <span class="hljs-subst">{testScore[<span class="hljs-number">2</span>] * <span class="hljs-number">100</span>}</span>%"</span>)
    print(<span class="hljs-string">f"Precisión media: <span class="hljs-subst">{testScore.mean() * <span class="hljs-number">100</span>}</span>%"</span>)
    print(<span class="hljs-string">"Success"</span>)

    drawGraphics(XX, y, XXval, yval, XXtest, ytest, svm, params, eTraining, eValidation, bestIndex)
</div></code></pre>
<p>Finalmente, no solo utilizamos <code>Xtest, ytest</code> para realizar la comprobación de resultados, aunque sus datos serían los más relevantes, sino que comprobamos la puntuación de cada grupo de datos, imprimiendo los cálculos en consola y mostrándolos mediante gráficas.</p>
<div style="page-break-after: always;"></div>
<h2 id="svm-resultados">SVM Resultados</h2>
<p><strong><code>Valores iniciales. sigma = 0.01, C = 0.01, iteraciones = 20</code></strong></p>
<h3 id="evoluci%C3%B3n-de-sigma">Evolución de Sigma</h3>
<h1 id=""></h1>
<p>En esta imagen podemos observar la evolución del parámetro <code>sigma</code> en función de <code>C</code>. A pesar de haber estado entrenando con 20 valores distintos para C y sigma, es decir, con 20 iteraciones para cada uno, resultaban gráficas que no mostraban ningún tipo de evolución pues el valor de los parámetros en ese instante no tenía ningún impacto. Así pues, mediante estas gráficas podemos observar como crece la precisión media de las predicciones, tanto para los datos de entrenamiento como los de validación, a medida que aumenta C, es decir, tal vez con mayores iteraciones y mayores valores de C podríamos obtener valores más precisos.</p>
<center>
<img src = "https://user-images.githubusercontent.com/47497948/150387765-342e1e33-d009-4881-90a0-9c114667312a.png" height = 500>
</center>
<div style="page-break-after: always;"></div>
<h3 id="evoluci%C3%B3n-de-c">Evolución de C</h3>
<h1 id=""></h1>
<p>Ahora bien, con estas gráficas observamos el efecto contrario, la evolución de <code>C</code> en función de <code>sigma</code>. En este caso, obtenemos menos gráficas relevantes pueso que los valores altos de sigma no otorgaban ningún tipo de impacto ni de beneficio al sistema de clasificación.</p>
<p><img src="https://user-images.githubusercontent.com/47497948/150390920-02d2b162-ad46-4f24-9355-9ce7dda7d086.png" alt="GraficasSVM-S"></p>
<h3 id="resultados">Resultados</h3>
<h1 id=""></h1>
<p>Como podemos observar, los mejores valores son: <code>C (reg) = 116226.</code> y <code>sigma = 17.7</code> otorgando las precisiones que se pueden observar en la imagen, calculadas mediante <code>svm.score</code>.</p>
<p><img src="https://user-images.githubusercontent.com/47497948/150391352-e0ad6fa6-e4b7-4a78-a0c5-f203127379a8.png" alt="resultados"></p>
<div style="page-break-after: always;"></div>
<h3 id="predicciones">Predicciones</h3>
<h1 id=""></h1>
<p>Finalmente, pusimos a prueba el sistema utilizando los mejores valores, obteniendo una gráfica de barras como la que se puede observar. En ella estamos comparando los valores reales con las predicciones, indicando el número de personas que hay por grado, a qué grado pertenecen y el porcentaje de precisión de esa columna.</p>
<p><img src="https://user-images.githubusercontent.com/47497948/150392097-0abeb671-ae8f-4669-8973-ad4dc32a4045.png" alt="BarsSVM"></p>
<div style="page-break-after: always;"></div>
<h1 id="sistema-de-regresi%C3%B3n-log%C3%ADstica">Sistema de Regresión Logística</h1>
<p>Para entrenar los datos mediante <code>Regresión Logística</code> hacemos uso de <strong><code>oneVsAll</code></strong>, donde hay que tener en cuenta dos parámetros: <strong><code>initReg</code></strong> e <strong><code>iters</code></strong>.</p>
<ul>
<li><strong><code>initReg</code></strong>`: sirve para inicializar el parámetro de regularización <strong><code>reg</code></strong>.</li>
<li><strong><code>iters</code></strong>: es el número de iteraciones que habrá para entrenar el término de regularización, de manera que pueda ofrecer los mejores resultados para <strong><code>theta</code></strong>.</li>
</ul>
<p>Para el entrenamiento, al igual que antes, tenemos en cuenta la mejor evaluación en función de los datos de validación <strong><code>Xval, yval</code></strong> y, finalmente, imprimimos los mejores resultados por consola.</p>
<pre class="hljs"><code><div><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">oneVsAll</span><span class="hljs-params">(X, y, Xval, yval, initReg=<span class="hljs-number">0.01</span>, iters=<span class="hljs-number">8</span>, num_labels=<span class="hljs-number">4</span>)</span>:</span>
    <span class="hljs-string">"""
    Entrenamiento de varios clasificadores por regresión logística
    """</span>
    numFeatures = X.shape[<span class="hljs-number">1</span>]
    <span class="hljs-comment"># Matriz de parámetros theta</span>
    theta = np.zeros((num_labels, numFeatures))
    perfmY = getLabelMatrixY(y, num_labels)
    <span class="hljs-comment"># Matriz de etiquetas yval</span>
    ylv = getLabelMatrixY(yval, num_labels)

    <span class="hljs-comment"># Entrenamiento</span>
    validation = np.zeros(num_labels)
    bestScore = np.zeros(num_labels)
    bestReg = np.zeros(num_labels)
    bestTheta = np.zeros((num_labels, numFeatures))

    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(num_labels):
        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(iters):
            reg = initReg * <span class="hljs-number">3</span>**j
            <span class="hljs-comment"># Se entrena con las X</span>
            result = opt.fmin_tnc(func = coste, x0 = theta[i, :], fprime = gradiente,
                    args=(X, perfmY[:, i], reg), disp=<span class="hljs-number">0</span>)
            theta[i, :] = result[<span class="hljs-number">0</span>]

            <span class="hljs-comment"># Se evalua con las Xval</span>
            <span class="hljs-comment"># Matriz de etiquetas yval</span>
            validation[i] = evalua(i, theta[i, :], Xval, ylv[:, i])
            <span class="hljs-keyword">if</span>(validation[i] &gt; bestScore[i]):
               bestScore[i] = validation[i] 
               bestReg[i] = reg
               bestTheta[i, :] = theta[i, :]

    <span class="hljs-keyword">return</span> bestScore, bestReg, bestTheta

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">logisticRegresionClassification</span><span class="hljs-params">(X, y, Xval, yval, Xtest, ytest)</span>:</span>
    <span class="hljs-string">"""
    Clasificación de los datos mediante Regresión Logística
    """</span>
    print(<span class="hljs-string">"Entrenando sistema de clasificación de bodyPerfomance"</span>)
    bestScore, bestReg, bestTheta = oneVsAll(X, y, Xval, yval)
    
    <span class="hljs-comment">#----------------PRINT-DATA----------------#</span>
    num_labels = <span class="hljs-number">4</span>

    print(<span class="hljs-string">"\n------------------------------------------"</span>)
    print(<span class="hljs-string">"\nMejores resultados del entrenamiento"</span>)
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(num_labels):
        str1 = <span class="hljs-string">f"Mejor reg <span class="hljs-subst">{chr(i + <span class="hljs-number">65</span>)}</span>: <span class="hljs-subst">{bestReg[i]}</span>"</span>
        str2 = <span class="hljs-string">f"Evaluación <span class="hljs-subst">{chr(i + <span class="hljs-number">65</span>)}</span>: <span class="hljs-subst">{bestScore[i] * <span class="hljs-number">100</span>}</span>%"</span> 
        print(str1 + <span class="hljs-string">" - "</span> + str2)
    
    print(<span class="hljs-string">f"Error: <span class="hljs-subst">{<span class="hljs-number">1</span> - bestScore.mean()}</span>"</span>)
    print(<span class="hljs-string">"Evaluación media: "</span>, bestScore.mean() * <span class="hljs-number">100</span>)
    print(<span class="hljs-string">"\n------------------------------------------"</span>)

    print(<span class="hljs-string">"\nComprobación de parámetros con ytest, Xtest"</span>)
    testResults = np.zeros(num_labels)
    <span class="hljs-comment"># Matriz ytest de etiquetas</span>
    ylt = getLabelMatrixY(ytest, num_labels)

    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(num_labels):
        testResults[i] = evalua(i, bestTheta[i, :], Xtest, ylt[:, i])
        print(<span class="hljs-string">f"Evaluación <span class="hljs-subst">{chr(i + <span class="hljs-number">65</span>)}</span>: <span class="hljs-subst">{testResults[i] * <span class="hljs-number">100</span>}</span>%"</span>)
    print(<span class="hljs-string">"Evaluación media test: "</span>, testResults.mean() * <span class="hljs-number">100</span>)

    print(<span class="hljs-string">"\n------------------------------------------"</span>)
    print(<span class="hljs-string">"Success"</span>)
   
    <span class="hljs-comment">#----------------GRAPHICS----------------#</span>


    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>
</div></code></pre>
<p>Por otro lado, hemos realizado el mismo sistema de entrenamiento, pero con el objetivo de averiguar cuál es el mejor par de atributos para predecir el resultado. Para ello, tenemos las siguientes funciones:</p>
<pre class="hljs"><code><div><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">calculatePair</span><span class="hljs-params">(X, Xval, i, j)</span>:</span>
    <span class="hljs-string">"""
    Devuelve el par correspondiente de datos
    """</span>
    numFeatures = <span class="hljs-number">2</span>
    pair = np.zeros((X.shape[<span class="hljs-number">0</span>], numFeatures))
    pair[:, <span class="hljs-number">0</span>] = X[:, i]
    pair[:, <span class="hljs-number">1</span>] = X[:, j]

    pair_val = np.zeros((Xval.shape[<span class="hljs-number">0</span>], numFeatures))
    pair_val[:, <span class="hljs-number">0</span>] = Xval[:, i]
    pair_val[:, <span class="hljs-number">1</span>] = Xval[:, j]

    <span class="hljs-keyword">return</span> pair, pair_val

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">bestPairClassification</span><span class="hljs-params">(X, y, Xval, yval, Xtest, ytest, dataset)</span>:</span>
    <span class="hljs-string">"""
    Clasificación de los datos mediantes Regresión Logística
    para cada par de datos, escogiendo los 2 mejores atributos
    que clasifiquen el resultado
    """</span>
    print(<span class="hljs-string">"Entrenando sistema de clasificación de bodyPerfomance"</span>)
    bestScore = np.zeros(<span class="hljs-number">1</span>)
    bestPair = <span class="hljs-number">0</span>
    bestReg = <span class="hljs-number">0</span>
    bestTheta = <span class="hljs-number">0</span>
    f1, f2 = <span class="hljs-number">0</span>, <span class="hljs-number">0</span>
    
    initReg = <span class="hljs-number">0.0003</span>
    n = <span class="hljs-number">1</span>
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(X.shape[<span class="hljs-number">1</span>]):
        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(i + <span class="hljs-number">1</span>, X.shape[<span class="hljs-number">1</span>]):
            pair, pair_val = calculatePair(X, Xval, i, j)
            score, reg, theta = oneVsAll(pair, y, pair_val, yval, initReg, <span class="hljs-number">10</span>)
            <span class="hljs-keyword">if</span>(score.mean() &gt; bestScore.mean()):
                bestScore = score
                bestPair = [pair, pair_val]
                bestReg = reg
                bestTheta = theta
                f1, f2 = i, j

    <span class="hljs-comment">#----------------PRINT-DATA----------------#</span>
    num_labels = <span class="hljs-number">4</span>
    features = dataset.columns[f1] + <span class="hljs-string">", "</span> + dataset.columns[f2]
    
    print(<span class="hljs-string">"\n------------------------------------------"</span>)
    
    print(<span class="hljs-string">"\nMejores resultados del entrenamiento"</span>)
    print(<span class="hljs-string">f"Mejor par de atributos: <span class="hljs-subst">{features}</span>"</span>)
    print(<span class="hljs-string">f"Mejor reg: <span class="hljs-subst">{bestReg}</span>"</span>)
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(num_labels):
        str1 = <span class="hljs-string">f"Mejor reg <span class="hljs-subst">{chr(i + <span class="hljs-number">65</span>)}</span>: <span class="hljs-subst">{bestReg[i]}</span>"</span>
        str2 = <span class="hljs-string">f"Evaluación <span class="hljs-subst">{chr(i + <span class="hljs-number">65</span>)}</span>: <span class="hljs-subst">{bestScore[i] * <span class="hljs-number">100</span>}</span>%"</span> 
        print(str1 + <span class="hljs-string">" - "</span> + str2)
    
    print(<span class="hljs-string">"Evaluación media: "</span>, bestScore.mean() * <span class="hljs-number">100</span>)
    print(<span class="hljs-string">f"Error: <span class="hljs-subst">{<span class="hljs-number">1</span> - bestScore.mean()}</span>"</span>)

    print(<span class="hljs-string">"\n------------------------------------------"</span>)

    print(<span class="hljs-string">"\nComprobación de parámetros con ytest, Xtest"</span>)
    testResults = np.zeros(num_labels)
    <span class="hljs-comment"># Matriz ytest de etiquetas</span>
    numFeatures = <span class="hljs-number">2</span>
    ylt = getLabelMatrixY(ytest, num_labels)
    pair_test = np.zeros((Xtest.shape[<span class="hljs-number">0</span>], numFeatures))
    pair_test[:, <span class="hljs-number">0</span>] = Xtest[:, f1]
    pair_test[:, <span class="hljs-number">1</span>] = Xtest[:, f2]

    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(num_labels):
        testResults[i] = evalua(i, bestTheta[i, :], pair_test, ylt[:, i])
        print(<span class="hljs-string">f"Evaluación <span class="hljs-subst">{chr(i + <span class="hljs-number">65</span>)}</span>: <span class="hljs-subst">{testResults[i] * <span class="hljs-number">100</span>}</span>%"</span>)
    print(<span class="hljs-string">"Evaluación media test: "</span>, testResults.mean() * <span class="hljs-number">100</span>)

    print(<span class="hljs-string">"\n------------------------------------------"</span>)

    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>
</div></code></pre>
<h2 id="regresi%C3%B3n-log%C3%ADstica-resultados">Regresión Logística resultados</h2>
<h3 id="resultados-con-todos-los-atributos">Resultados con todos los atributos</h3>
<h1 id=""></h1>
<p><strong><code>Valores iniciales. initReg=0.01, iters=8</code></strong></p>
<p>Aquí podemos observar que el mejor término de regularización no es el mismo para predecir los resultados, es deicr, para los grados <strong><code>A y B</code></strong> obtenemos un valor de <strong><code>7.29</code></strong> y para <strong><code>C y D</code></strong> de <strong><code>0.01</code></strong>.</p>
<p><img src="https://user-images.githubusercontent.com/47497948/150401103-d496dc51-f72e-4036-8253-4cd281d4d9c3.png" alt="resultados1"></p>
<div style="page-break-after: always;"></div>
<h3 id="resultados-del-mejor-par-de-atributos">Resultados del mejor par de atributos</h3>
<h1 id=""></h1>
<p><strong><code>Valores iniciales. initReg = 0.0003, iters=10</code></strong></p>
<p>Finalmente, obtenemos que el mejor par de atributos para predecir los resultados sería el que está compuesto por <strong><em>sit_bend_forw_cm</em> y <em>sit_ups_counts</em></strong>, que son básicamente dos tipos de ejercicios físicos que se realizan durante el <em>BodyPerformance</em>. Además, lo más curioso a destacar es que la precisión es prácticamente la misma que la obtenida con todos los atributos, por lo que de cara a una mejora en el sistema, sería interesante pensar en cómo utilizar el menor número de atibutos para realizar la predicción.</p>
<p><img src="https://user-images.githubusercontent.com/47497948/150401478-ffe1bca0-82d8-4325-a3c9-12c0b7b4d2d6.png" alt="resultados2"></p>
<div style="page-break-after: always;"></div>
<h1 id="sistema-de-redes-neuronales">Sistema de Redes Neuronales</h1>
<p>En primer lugar se inicializan los pesos de forma aleatoria (<strong><code>Theta1</code></strong> y <strong><code>Theta2</code></strong>). Luego se implementa <strong><code>forward propagation</code></strong> para obtener la <strong><code>hipótesis</code></strong>, seguido de la implementación de la <strong><code>función de coste</code></strong>.  Posteriormente, se implementa <strong><code>backpropagation</code></strong> para computar las derivadas parciales. Finalmente, se utiliza el <strong><code>descenso del gradiente</code></strong> para encontrar los mejores parámetros.</p>
<p>La red neuronal está constituida por 3 capas, de manera que en la primera se encuentra la <strong><code>capa de entrada</code></strong> que tiene tantos nodos como atributos tenga el dataset. Luego nos encontramos con las <strong><code>capas oculas</code></strong> donde hemos escogido el número de capas ocultas mediante prueba y error hasta encontrar un número que nos satisfaga. Por último, se encuentra la <strong><code>capa de salida</code></strong> que tiene tantos nodos como tipo de resultados tiene nuestro dataset.</p>
<p>Ahora bien, para entrenar la red neuronal hay que tener en cuenta los siguientes parámetros: <strong><code>número de capas oculas</code></strong>, <strong><code>número de nodos en la capa oculta</code></strong>, <strong><code>epsilon</code></strong>, <strong><code>número de iteraciones para el backpropagation</code></strong> y <strong><code>lambda</code></strong>.</p>
<p>Además, se han realizado pruebas con diferentes tamaños en el dataset, escogiendo el <strong><code>10%</code></strong> del total de los datos y el <strong><code>100%</code></strong></p>
<p>También hemos utilizado la función de <em>checking</em> otorgada en la <code>práctica 4</code> para comprobar que el <em>backpropagation</em> funciona correctamente.</p>
<p>Por otro lado, para realizar un correcto entrenamiento hacemos uso de <strong><code>cross-validation</code></strong> combinando el mínimo error y el mejor resultado de precisión en cada iteración, de manera que hemos realizado la siguiente fórmula:</p>
<pre class="hljs"><code><div>special_cost = Jval[i]/<span class="hljs-number">10</span> + diff/<span class="hljs-number">4</span>
</div></code></pre>
<p>La razón de hacer esto es porque no queríamos que la varianza entre los datos de entrenamiento y los datos de validación fuese demasiado grande, pero tampoco queríamos resultados poco precisos, por lo que, de nuevo, mediante prueba y error, conseguimos combinar ambos términos para tener en cuenta la distancia mínima entre cada curva de aprendizaje del error y el mejor resultado de precisión de los datos de validación.</p>
<pre class="hljs"><code><div><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">make_neural_network</span><span class="hljs-params">(input_layer, hidden_layer, output_layer, X, y_labels, lamb, iteration, epsilon)</span>:</span>
    <span class="hljs-comment"># Initialize the thetas random values between -eps and eps</span>
    weights_size = hidden_layer * (input_layer + <span class="hljs-number">1</span>) + output_layer * (hidden_layer + <span class="hljs-number">1</span>)
    weights = np.random.uniform(-epsilon, epsilon, weights_size)

    <span class="hljs-comment"># Calculate the best thetas</span>
    result = opt.minimize(fun = backprop, x0 = weights,
                    args = (input_layer, hidden_layer, output_layer, X, y_labels, lamb), 
                    method=<span class="hljs-string">'TNC'</span>, jac=<span class="hljs-literal">True</span>, options={<span class="hljs-string">'maxiter'</span>: iteration})
    <span class="hljs-comment"># As the result is an array we remake the thetas matrixes with the corespondent sizes</span>
    optT1 = np.reshape(result.x[:hidden_layer * (input_layer + <span class="hljs-number">1</span>)], (hidden_layer, (input_layer + <span class="hljs-number">1</span>)))
    optT2 = np.reshape(result.x[hidden_layer * (input_layer + <span class="hljs-number">1</span>):], (output_layer, (hidden_layer + <span class="hljs-number">1</span>)))
    <span class="hljs-keyword">return</span> optT1, optT2

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">neuralNetworkClassification</span><span class="hljs-params">(X, y, Xval, yval, Xtest, ytest)</span>:</span>
    <span class="hljs-string">"""
    Clasificación de los datos mediante Redes Neuronales
    """</span>
    <span class="hljs-comment"># We remember the path for the graphics</span>
    script_dir = os.path.dirname(__file__)
    result_dir = script_dir[:<span class="hljs-number">-4</span>] + <span class="hljs-string">'\\memoria\\assets\\neu_net\\'</span>

    <span class="hljs-comment"># Initialize variables</span>
    num_features = X.shape[<span class="hljs-number">1</span>]
    num_labels = <span class="hljs-number">4</span>
    y_labels = getLabelMatrixY(y, num_labels)
    yval_labels = getLabelMatrixY(yval, num_labels)
    <span class="hljs-comment"># Epsilon</span>
    init_epsilon = <span class="hljs-number">0.1</span>
    epsilons = <span class="hljs-number">6</span>
    best_eps = <span class="hljs-number">0.1</span>

    <span class="hljs-comment"># NeuralNet</span>
    neural_net_iters = <span class="hljs-number">200</span> <span class="hljs-comment"># 100</span>
    hid = <span class="hljs-number">75</span>    <span class="hljs-comment"># 25</span>
    input_layer = num_features
    output_layer = num_labels

    <span class="hljs-comment"># Lambdas</span>
    initLambda = <span class="hljs-number">0.01</span>
    lambdas = np.zeros(<span class="hljs-number">7</span>)
    best_lambda = <span class="hljs-number">0.01</span>
    
    <span class="hljs-comment"># Misc</span>
    min_cost = np.inf
    best_percent = <span class="hljs-number">-1</span>
    best_optT1 = []
    best_optT2 = []
    min_diff = np.inf
    min_special_cost = np.inf
    <span class="hljs-comment"># Notas: No hace falta repetir tanto el código, solo con esta cadena de for funciona</span>
    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(epsilons):
        epsilon = init_epsilon + <span class="hljs-number">0.02</span> * j
        Jval = np.ones(len(lambdas))
        Jtraining = np.ones(len(lambdas))
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(lambdas)):
            <span class="hljs-comment"># Training with X</span>
            lambdas[i] = initLambda * <span class="hljs-number">3</span>**i
            optT1, optT2 = make_neural_network(input_layer, hid, output_layer, X,
                                        y_labels, lambdas[i], neural_net_iters, epsilon)

            print(<span class="hljs-string">f"Lambda <span class="hljs-subst">{lambdas[i]}</span>   Epsilon: <span class="hljs-subst">{epsilon}</span> Iterations:"</span>
                + <span class="hljs-string">f"<span class="hljs-subst">{neural_net_iters}</span> Hidden layers: <span class="hljs-subst">{hid}</span>"</span>)

            <span class="hljs-comment"># We calculate the percentages of succes and using them we calculate the error for the training data set and cross validation data set</span>
            Jtraining[i] = <span class="hljs-number">10</span> - get_total_percent(<span class="hljs-string">'training'</span>, X, y, optT1, optT2)/<span class="hljs-number">10</span>
            current_percent = get_total_percent(<span class="hljs-string">'validation'</span>, Xval, yval, optT1, optT2)
            Jval[i] = <span class="hljs-number">10</span> - current_percent/<span class="hljs-number">10</span>
            <span class="hljs-comment"># Jtraining[i] = J(optT1, optT2, X, y_labels)</span>
            <span class="hljs-comment"># Jval[i] = J(optT1, optT2, Xval, yval_labels)</span>

            diff = np.abs(Jtraining[i] - Jval[i])
            <span class="hljs-comment"># We remember the thetas that have the smallest error(biggest percent) on the cross validation data set but also the minimum distance </span>
            special_cost = Jval[i]/<span class="hljs-number">10</span> + diff/<span class="hljs-number">4</span>
            <span class="hljs-keyword">if</span>  Jval[i] &lt; min_cost:
                min_cost = Jval[i]
                min_cost_lamb = lambdas[i]
                min_cost_eps = epsilon
            <span class="hljs-keyword">if</span> diff &lt; min_diff:
                min_diff = diff
                diff_lamb = lambdas[i]
                diff_eps = epsilon
            <span class="hljs-keyword">if</span>  special_cost &lt; min_special_cost: <span class="hljs-comment">#Combined distance and cost</span>
                min_special_cost = special_cost
                best_percent = current_percent
                best_lambda = lambdas[i]
                best_eps = epsilon
                best_optT1 = optT1
                best_optT2 = optT2
            print(<span class="hljs-string">"\n"</span>)

        <span class="hljs-comment"># We prepare the parameters for the graphics</span>
        name = <span class="hljs-string">'Lambda'</span> + <span class="hljs-string">'LearningCurve'</span> + <span class="hljs-string">'_it_'</span> + str(neural_net_iters) + <span class="hljs-string">'_hidd_'</span> + str(hid) + <span class="hljs-string">'_eps_'</span> + str(round(epsilon,<span class="hljs-number">2</span>)) + <span class="hljs-string">'_sizex_'</span> + str(X.shape[<span class="hljs-number">0</span>])+<span class="hljs-string">'.png'</span>
        path = result_dir + name
        parameters = <span class="hljs-string">'Hidden layer = '</span> + str(hid) + <span class="hljs-string">' '</span> + <span class="hljs-string">'Iterations = '</span> + str(neural_net_iters) + <span class="hljs-string">' '</span> + <span class="hljs-string">'$\epsilon$ = '</span> + str(round(epsilon,<span class="hljs-number">2</span>))
        create_learning_curve_graphic(path, parameters, lambdas, Jtraining, Jval, label = <span class="hljs-string">"$\lambda$"</span>)
    print()
    print(<span class="hljs-string">fr"Min Diff: <span class="hljs-subst">{round(min_diff,<span class="hljs-number">2</span>)}</span> lamb: <span class="hljs-subst">{diff_lamb}</span> epsilon: <span class="hljs-subst">{round(diff_eps,<span class="hljs-number">2</span>)}</span>"</span>)
    print(<span class="hljs-string">fr"Min Cost <span class="hljs-subst">{round(min_cost,<span class="hljs-number">2</span>)}</span> Max Percent: <span class="hljs-subst">{<span class="hljs-number">10</span> - round(min_cost,<span class="hljs-number">2</span>)}</span> lamb: <span class="hljs-subst">{min_cost_lamb}</span> epsilon: <span class="hljs-subst">{min_cost_eps}</span>"</span>)
    print(<span class="hljs-string">fr"Mejor lambda: <span class="hljs-subst">{best_lambda}</span>"</span>)
    print(<span class="hljs-string">fr"Mejor epsilon: <span class="hljs-subst">{round(best_eps,<span class="hljs-number">2</span>)}</span>"</span>)
    print(<span class="hljs-string">f"Precisión mejor validación: <span class="hljs-subst">{round(best_percent,<span class="hljs-number">2</span>)}</span> best cost: <span class="hljs-subst">{<span class="hljs-number">100</span> - round(best_percent,<span class="hljs-number">2</span>)}</span>"</span>)
    get_total_percent(<span class="hljs-string">'Current best test'</span>, Xtest, ytest, best_optT1, best_optT2)

    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>
</div></code></pre>
<h2 id="redes-neuronales-resultados">Redes Neuronales resultados</h2>
<h1 id="10-de-los-datos">10% de los datos</h1>
<h1 id=""></h1>
<p><strong><code>Valores iniciales. hidden_layers = 25, iters = 100, size_training_set = 803 (10% of the data)</code></strong></p>
<p>Con esta cantidad de datos podemos ver claramente la influencia de lambda en el dataset, por lo que podemos ver cuando hay sesgo y varianza. Cuando el error es alto, la función está desajustada (cuanto mayor sea lambda, mayor será el sesgo, por lo que las líneas comenzarán a juntarse). Por otro lado, cuando los datos de entrenamiento tienen poco error y los de validación tienen mucho, el sistema comienza a sobreajustarse.</p>
<p>Por ello, la mejor gráfica será la que porta una estrella, pues es en la que se muestra como la solución tiene poco error y también los datos están bastante cercanos los unos a los otros.</p>
<p><img src="https://user-images.githubusercontent.com/47497948/150422701-0909a83a-301c-43f0-9ecc-3b278f12cee3.png" alt="iter 100 hid 25 sizeX 803"></p>
<img src="https://user-images.githubusercontent.com/47497948/150422876-503930bb-5729-41aa-8dd0-955c120cc9ce.PNG">
<h1 id="100-de-los-datos">100% de los datos</h1>
<p>A continuación podemos observar diferentes gráficas con diferentes datos, aplicando lo que acabamos de explicar</p>
<h1 id=""></h1>
<p><strong><code>Valores iniciales. hidden_layers = 25, iters = 100</code></strong></p>
<p><img src="https://user-images.githubusercontent.com/47497948/150424564-8ab11b3f-404e-4224-990b-86b17eefdec0.png" alt="iter 100 hid 25 sizeX 8035 BIG"></p>
<img src="https://user-images.githubusercontent.com/47497948/150424602-524c7ee0-7fe6-44b3-a0ee-0faaf10fb6d3.PNG">
<h1 id=""></h1>
<p><strong><code>Valores iniciales. hidden_layers = 75, iters = 200</code></strong></p>
<p><img src="https://user-images.githubusercontent.com/47497948/150424783-5db6a331-dff0-4235-98de-75a0c2749814.png" alt="iter 200 hid 75 sizeX 8035 BIG"></p>
<img src="https://user-images.githubusercontent.com/47497948/150424850-039d83c1-c9fb-409e-82eb-a004aca89262.PNG">
<p>Como podemos observar al ajustar diversos parámetros, en este caso aumentando <strong><code>iterations</code></strong> y <strong><code>hidden_layers</code></strong>, hemos ido encontrando poco a poco los mejores resultados para clasificar nuestros datos.</p>

</body>
</html>
